{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.util import filter_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../ner-wikipedia-dataset/ner.json\") as f:\n",
    "    stock_mark_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データをSpacyで読み込める形式に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stockmark_to_spacy_train_data(stock_mark_data: list) -> list:\n",
    "    spacy_train_data = []\n",
    "    for data in stock_mark_data:\n",
    "        text = data[\"text\"]\n",
    "        entities = data[\"entities\"]\n",
    "\n",
    "        spacy_entites = [(entity[\"span\"][0], entity[\"span\"][1], entity[\"type\"]) for entity in entities]\n",
    "\n",
    "        spacy_train = {\"text\": text, \"entities\": spacy_entites}\n",
    "\n",
    "        spacy_train_data.append(spacy_train)\n",
    "    return spacy_train_data\n",
    "\n",
    "spacy_data = stockmark_to_spacy_train_data(stock_mark_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split_to_train_dev_test(spacy_data: list) -> tuple[list, list, list]:\n",
    "    all_len = len(spacy_data)\n",
    "\n",
    "    train_len = int(all_len * 0.6)\n",
    "    dev_len = train_len + int(all_len * 0.2)\n",
    "\n",
    "    random.shuffle(spacy_data)\n",
    "\n",
    "    train = spacy_data[:train_len]\n",
    "    dev = spacy_data[train_len:dev_len]\n",
    "    test = spacy_data[dev_len:]\n",
    "\n",
    "    return train, dev, test\n",
    "\n",
    "train, dev, test = random_split_to_train_dev_test(spacy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3205\n",
      "1068\n",
      "1070\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(dev))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 193/3205 [00:00<00:01, 1927.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 423/3205 [00:00<00:01, 2142.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 883/3205 [00:00<00:01, 2242.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 1116/3205 [00:00<00:00, 2268.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2484/3205 [00:01<00:00, 2181.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 2936/3205 [00:01<00:00, 2221.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3205/3205 [00:01<00:00, 2232.97it/s]\n",
      " 42%|████▏     | 453/1068 [00:00<00:00, 2263.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1068/1068 [00:00<00:00, 2376.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 215/1070 [00:00<00:00, 2148.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 690/1070 [00:00<00:00, 2335.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 930/1070 [00:00<00:00, 2360.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1070/1070 [00:00<00:00, 2325.05it/s]\n"
     ]
    }
   ],
   "source": [
    "def make_spacy(data: list, name: str) -> None:\n",
    "    nlp = spacy.blank(\"ja\") # load a new spacy model\n",
    "    db = DocBin()\n",
    "    for training_example in tqdm(data):\n",
    "        text = training_example['text']\n",
    "        annotations = training_example['entities']\n",
    "        doc = nlp(text)\n",
    "        ents = []\n",
    "        for start, end, label in annotations:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "\n",
    "            if span is None:\n",
    "                print(\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    db.to_disk(f\"../data/{name}.spacy\")\n",
    "\n",
    "make_spacy(data=train, name=\"train\")\n",
    "make_spacy(data=dev, name=\"dev\")\n",
    "make_spacy(data=test, name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sansan株式会社\n",
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "text = \"Sansan株式会社は、「出会いからイノベーションを生み出す」をミッションとして掲げています\"\n",
    "start = 0\n",
    "end = 10\n",
    "label = \"法人名\"\n",
    "\n",
    "nlp = spacy.blank(\"ja\")\n",
    "doc = nlp(text)\n",
    "span = doc.char_span(start, end, label=label)\n",
    "\n",
    "print(span)\n",
    "print(type(span))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "期待出力: 草戸稲荷神社\n",
      "実際の出力: None\n",
      "データ型: <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "text = \"また、草戸稲荷神社前には遊女町を造ったといわれる。\"\n",
    "start = 3\n",
    "end = 9\n",
    "label = \"施設名\"\n",
    "\n",
    "nlp = spacy.blank(\"ja\")\n",
    "doc = nlp(text)\n",
    "span = doc.char_span(start, end, label=label)\n",
    "\n",
    "print(f\"期待出力: {text[start:end]}\")\n",
    "print(f\"実際の出力: {span}\")\n",
    "print(f\"データ型: {type(span)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[また, 、, 草戸, 稲荷, 神社前, に, は, 遊女, 町, を, 造っ, た, と, いわ, れる, 。]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"ja\")\n",
    "doc = nlp(\"また、草戸稲荷神社前には遊女町を造ったといわれる。\")\n",
    "print([token for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configファイルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "../config/config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ../config/base_config.cfg ../config/config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-07-18 13:22:36,897] [INFO] Set up nlp object from config\n",
      "[2023-07-18 13:22:36,903] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2023-07-18 13:22:36,904] [INFO] Created vocabulary\n",
      "[2023-07-18 13:22:37,509] [INFO] Added vectors: ja_core_news_lg\n",
      "[2023-07-18 13:22:37,509] [INFO] Finished initializing nlp object\n",
      "[2023-07-18 13:22:42,643] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     51.24    0.39    0.44    0.34    0.00\n",
      "  0     200        190.58   3211.08    9.95   13.77    7.79    0.10\n",
      "  0     400        347.40   3210.15   22.88   25.64   20.66    0.23\n",
      "  0     600        434.84   3822.97   25.66   26.96   24.48    0.26\n",
      "  0     800        591.75   4287.12   49.33   53.35   45.87    0.49\n",
      "  1    1000        537.14   4037.01   53.18   60.57   47.40    0.53\n",
      "  1    1200        534.45   4901.46   58.87   60.44   57.37    0.59\n",
      "  2    1400        711.85   4882.69   62.10   63.28   60.96    0.62\n",
      "  3    1600        685.79   4994.82   63.05   64.90   61.31    0.63\n",
      "  4    1800        930.35   5243.22   65.50   65.88   65.13    0.66\n",
      "  5    2000        991.17   5170.50   65.26   64.80   65.74    0.65\n",
      "  7    2200       1321.20   5442.88   66.80   68.05   65.58    0.67\n",
      "  8    2400       1367.29   4889.70   67.09   68.14   66.08    0.67\n",
      " 10    2600       1236.35   4184.37   68.83   71.03   66.77    0.69\n",
      " 12    2800       1308.38   3499.83   69.17   71.76   66.77    0.69\n",
      " 14    3000       1047.02   2579.08   68.99   70.81   67.27    0.69\n",
      " 16    3200       1028.03   2498.71   67.83   69.54   66.20    0.68\n",
      " 17    3400        839.76   1836.57   69.78   70.84   68.75    0.70\n",
      " 19    3600       1011.09   1742.63   70.17   72.27   68.18    0.70\n",
      " 21    3800        751.66   1484.94   69.19   70.31   68.11    0.69\n",
      " 23    4000        673.49   1107.12   71.01   73.20   68.95    0.71\n",
      " 25    4200        766.59   1041.68   70.31   73.98   67.00    0.70\n",
      " 26    4400        998.40    861.38   70.06   71.25   68.91    0.70\n",
      " 28    4600        687.66    760.06   70.90   71.45   70.36    0.71\n",
      " 30    4800        827.27    783.79   70.78   72.58   69.06    0.71\n",
      " 32    5000        779.15    605.75   71.36   74.17   68.75    0.71\n",
      " 34    5200        714.10    565.83   71.09   75.22   67.38    0.71\n",
      " 35    5400        853.68    586.68   71.04   73.84   68.45    0.71\n",
      " 37    5600       1250.54    795.33   69.76   73.82   66.12    0.70\n",
      " 39    5800       1471.52    769.59   70.43   70.90   69.98    0.70\n",
      " 41    6000        772.33    508.33   71.91   72.75   71.08    0.72\n",
      " 43    6200       1064.15    566.58   70.86   72.14   69.63    0.71\n",
      " 45    6400       1041.60    609.14   71.40   71.91   70.89    0.71\n",
      " 46    6600       1446.74    591.34   70.90   71.50   70.32    0.71\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train ../config/config.cfg --output ./ --paths.train ../data/train.spacy --paths.dev ../data/dev.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK     100.00\n",
      "NER P   68.37 \n",
      "NER R   67.26 \n",
      "NER F   67.81 \n",
      "SPEED   1556  \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "              P       R       F\n",
      "イベント名     74.68   55.02   63.36\n",
      "地名        78.49   83.86   81.09\n",
      "製品名       40.33   53.30   45.92\n",
      "施設名       71.60   56.02   62.86\n",
      "法人名       64.05   69.50   66.67\n",
      "政治的組織名    74.65   72.65   73.64\n",
      "人名        75.18   74.52   74.85\n",
      "その他の組織名   65.77   44.14   52.83\n",
      "\n",
      "\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n",
      "../evaluate_result\n",
      "\u001b[38;5;2m✔ Saved results to ../evaluate_result/test_metrics.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy benchmark accuracy model-best ../data/test.spacy --output ../evaluate_result/test_metrics.json --displacy-path ../evaluate_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>働き方を変えるDXサービスを提供する\n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sansan株式会社\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">法人名</span>\n",
       "</mark>\n",
       "は、契約DXサービス「\n",
       "<mark class=\"entity\" style=\"background: #7DF6D9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Contract One\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">製品名</span>\n",
       "</mark>\n",
       "」がサービス価値向上を目的に、\n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    マイクロソフト社\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">法人名</span>\n",
       "</mark>\n",
       "が提供するAzure OpenAI Serviceを活用した「\n",
       "<mark class=\"entity\" style=\"background: #7DF6D9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Contract One AI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">製品名</span>\n",
       "</mark>\n",
       "」を搭載したことを発表します。</br>今回は第一弾として文章内検索機能を追加します。契約書の内容について、定型質問から選択または質問内容を直接問いかけると、「\n",
       "<mark class=\"entity\" style=\"background: #7DF6D9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Contract One AI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">製品名</span>\n",
       "</mark>\n",
       "」が適切な情報を抽出し質問に回答します。本機能の追加によって、法務担当者に限らず誰もが早く、簡単に契約情報を把握することが可能となります。「\n",
       "<mark class=\"entity\" style=\"background: #7DF6D9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Contract One AI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">製品名</span>\n",
       "</mark>\n",
       "」は順次アップデートしていく予定です。</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = spacy.load(\"model-best\")\n",
    "\n",
    "text = \"\"\"\n",
    "働き方を変えるDXサービスを提供するSansan株式会社は、契約DXサービス「Contract One」がサービス価値向上を目的に、マイクロソフト社が提供するAzure OpenAI Serviceを活用した「Contract One AI」を搭載したことを発表します。\n",
    "今回は第一弾として文章内検索機能を追加します。契約書の内容について、定型質問から選択または質問内容を直接問いかけると、「Contract One AI」が適切な情報を抽出し質問に回答します。本機能の追加によって、法務担当者に限らず誰もが早く、簡単に契約情報を把握することが可能となります。「Contract One AI」は順次アップデートしていく予定です。\n",
    "\"\"\"\n",
    "\n",
    "colors = {\"法人名\": \"#F67DE3\", \"製品名\": \"#7DF6D9\"}\n",
    "options = {\"colors\": colors} \n",
    "\n",
    "doc = model(text)\n",
    "\n",
    "spacy.displacy.render(doc, style=\"ent\", options=options, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
